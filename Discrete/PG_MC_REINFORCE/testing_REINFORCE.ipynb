{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from time import sleep\n",
    "\n",
    "from REINFORCE import MCPGAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(agent, env, sleep_sec: float = 0.01, mode: str = \"rgb_array\"):\n",
    "    state = env.reset()\n",
    "    state_size = env.observation_space.shape[0]\n",
    "\n",
    "    if mode == \"rgb_array\":\n",
    "        steps = 0\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        action = agent.act(state)\n",
    "\n",
    "        state, _, done, _ = env.step(action)\n",
    "\n",
    "        if mode == \"rgb_array\":\n",
    "            steps += 1\n",
    "            frame = env.render()\n",
    "            ax.cla()\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "            ax.imshow(frame)\n",
    "            ax.set_title(f'Steps: {steps}')\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            plt.pause(sleep_sec)\n",
    "        else:\n",
    "            env.render()\n",
    "            sleep(sleep_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize environment\n",
    "env = gym.make('LunarLander-v2')\n",
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.shape[0]\n",
    "\n",
    "# set seed\n",
    "seed = 31\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "episodes = 10 # run agent for this many episodes\n",
    "hidden_size = 256 # number of units in NN hidden layers\n",
    "actor_lr = 0.002 # learning rate for actor\n",
    "value_function_lr = 0.002 # learning rate for value function\n",
    "discount = 0.99 # discount factor gamma value\n",
    "reward_scale = 0.01 #scale reward by this amount\n",
    "\n",
    "# create agent\n",
    "agent = MCPGAgent(state_size, \n",
    "                action_size, \n",
    "                actor_lr, \n",
    "                value_function_lr, \n",
    "                discount,\n",
    "                hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved actor and value function networks\n",
    "agent.actor_net.load_state_dict(torch.load('Trained_Agents/MC_actor.pth'))\n",
    "agent.vf_net.load_state_dict(torch.load('Trained_Agents/MC_valueF.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10, total reward: 91.95\n",
      "Episode 2/10, total reward: 65.24\n",
      "Episode 3/10, total reward: 110.31\n",
      "Episode 4/10, total reward: 127.36\n",
      "Episode 5/10, total reward: 96.32\n",
      "Episode 6/10, total reward: 120.42\n",
      "Episode 7/10, total reward: 119.32\n",
      "Episode 8/10, total reward: 151.78\n",
      "Episode 9/10, total reward: 49.19\n",
      "Episode 10/10, total reward: 107.58\n"
     ]
    }
   ],
   "source": [
    "# set the agent to evaluation mode\n",
    "agent.actor_net.eval()\n",
    "agent.vf_net.eval()\n",
    "\n",
    "# run the agent for a few episodes and print the total reward for each episode\n",
    "cumulative_reward = 0\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "    print(f'Episode {i+1}/10, total reward: {total_reward:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape () for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# no seed so different each time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# the goal is to reach an average score on training of at least 200 so that each run is a win\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mshow_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msleep_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mshow_video\u001b[0;34m(agent, env, sleep_sec, mode)\u001b[0m\n\u001b[1;32m     19\u001b[0m ax\u001b[38;5;241m.\u001b[39mcla()\n\u001b[1;32m     20\u001b[0m ax\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m display(fig)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5751\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5751\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5752\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5754\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/matplotlib/image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape () for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# no seed so different each time\n",
    "# the goal is to reach an average score on training of at least 200 so that each run is a win\n",
    "show_video(agent, env, sleep_sec=1e-5)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
